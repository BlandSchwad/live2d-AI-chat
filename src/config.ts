export default {
  // config
  backend_endpoint: "http://localhost:3000",
  openai_endpoint: "http://localhost:11434/v1",
  openai_apikey: "",
  openai_model_name: "llama3.1", // ni
};
